# üì§ Guide d'Upload vers AWS

Ce guide explique comment uploader manuellement les donn√©es JSON vers AWS apr√®s traitement sur EC2.

---

## üìã Nouveau Workflow

### 1Ô∏è‚É£ **Sur EC2 : Traitement des donn√©es**

Le syst√®me stocke maintenant **automatiquement** les donn√©es en JSON local :

```bash
# Sur EC2
cd /home/ec2-user/cityflow-project
./run_processing.sh
```

**R√©sultat :**
```
output/
‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îú‚îÄ‚îÄ bikes_metrics_2025-11-04.json
‚îÇ   ‚îú‚îÄ‚îÄ traffic_metrics_2025-11-04.json
‚îÇ   ‚îú‚îÄ‚îÄ weather_metrics_2025-11-04.json
‚îÇ   ‚îú‚îÄ‚îÄ comptages_metrics_2025-11-04.json
‚îÇ   ‚îú‚îÄ‚îÄ chantiers_metrics_2025-11-04.json
‚îÇ   ‚îî‚îÄ‚îÄ referentiel_metrics_2025-11-04.json
‚îî‚îÄ‚îÄ reports/
    ‚îú‚îÄ‚îÄ daily_report_2025-11-04.json
    ‚îî‚îÄ‚îÄ daily_report_2025-11-04.csv
```

‚úÖ **Plus besoin de DynamoDB** pendant le traitement !

---

### 2Ô∏è‚É£ **Upload manuel vers AWS**

Quand vous √™tes pr√™t, uploadez les donn√©es :

#### **Upload tout (m√©triques + rapports)**
```bash
python upload_to_aws.py
```

#### **Upload une date sp√©cifique**
```bash
python upload_to_aws.py --date 2025-11-04
```

#### **Upload seulement les m√©triques**
```bash
python upload_to_aws.py --type metrics
```

#### **Upload seulement les rapports**
```bash
python upload_to_aws.py --type reports
```

#### **Mode simulation (voir ce qui serait upload√©)**
```bash
python upload_to_aws.py --dry-run
```

---

## üîß Configuration requise

### **1. Tables DynamoDB**

Cr√©ez les tables avant l'upload :

```bash
# Script de cr√©ation des tables
python setup_dynamodb_tables.py
```

Ou manuellement dans la console AWS :

**Table 1: `cityflow-metrics`**
- Partition key: `metric_type` (String)
- Sort key: `date` (String)
- Billing: On-demand ou 5 RCU / 5 WCU

**Table 2: `cityflow-reports`**
- Partition key: `report_id` (String)
- Sort key: `date` (String)
- Billing: On-demand ou 5 RCU / 5 WCU

### **2. Bucket S3**

Cr√©ez le bucket pour les rapports :

```bash
aws s3 mb s3://cityflow-reports-paris --region eu-west-3
```

### **3. IAM Role EC2**

Votre EC2 doit avoir ces permissions :

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:PutItem",
        "dynamodb:GetItem",
        "dynamodb:UpdateItem"
      ],
      "Resource": [
        "arn:aws:dynamodb:eu-west-3:*:table/cityflow-metrics",
        "arn:aws:dynamodb:eu-west-3:*:table/cityflow-reports"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject"
      ],
      "Resource": [
        "arn:aws:s3:::cityflow-reports-paris/*"
      ]
    }
  ]
}
```

### **4. Fichier `.env` sur EC2**

```bash
# R√©gion AWS
AWS_REGION=eu-west-3

# Tables DynamoDB
DYNAMODB_METRICS_TABLE=cityflow-metrics
DYNAMODB_REPORTS_TABLE=cityflow-reports

# Bucket S3
S3_REPORTS_BUCKET=cityflow-reports-paris
S3_REPORTS_PREFIX=reports

# Chemins locaux (sur EC2)
DATA_DIR=/home/ec2-user/cityflow-project/data
BATCH_DATA_PATH=/home/ec2-user/cityflow-project/data/cityflow-raw/raw/batch
API_DATA_PATH=/home/ec2-user/cityflow-project/data/cityflow-raw/raw/api
OUTPUT_DIR=/home/ec2-user/cityflow-project/output
```

---

## üìä Exemple d'utilisation compl√®te

```bash
# 1. Traiter les donn√©es (g√©n√®re les JSON)
./run_processing.sh

# 2. V√©rifier les fichiers g√©n√©r√©s
ls -lh output/metrics/
ls -lh output/reports/

# 3. Tester l'upload en mode simulation
python upload_to_aws.py --dry-run

# 4. Upload r√©el vers AWS
python upload_to_aws.py

# 5. V√©rifier dans AWS
aws dynamodb scan --table-name cityflow-metrics --max-items 5
aws s3 ls s3://cityflow-reports-paris/reports/
```

---

## ‚úÖ Avantages de cette approche

1. **Pas de d√©pendance DynamoDB** pendant le traitement
2. **Flexibilit√©** : vous choisissez quand uploader
3. **√âconomies** : pas d'√©critures DynamoDB inutiles pendant les tests
4. **Backup local** : tous les fichiers JSON restent sur EC2
5. **Debugging facile** : fichiers JSON lisibles et modifiables
6. **Upload s√©lectif** : uploadez seulement certaines dates/types

---

## üîç D√©pannage

### **Erreur : "Table does not exist"**

‚û°Ô∏è Cr√©ez les tables DynamoDB :
```bash
python setup_dynamodb_tables.py
```

### **Erreur : "Access Denied"**

‚û°Ô∏è V√©rifiez le role IAM de votre EC2 :
```bash
aws sts get-caller-identity
aws iam get-role --role-name NomDeVotreRole
```

### **Erreur : "boto3 not found"**

‚û°Ô∏è Installez boto3 :
```bash
pip install boto3
```

### **Fichiers manquants**

‚û°Ô∏è V√©rifiez que le traitement s'est bien termin√© :
```bash
ls -lh output/metrics/
ls -lh output/reports/
```

---

## üéØ R√©sum√© des commandes

| Action | Commande |
|--------|----------|
| Traiter les donn√©es | `./run_processing.sh` |
| Voir fichiers g√©n√©r√©s | `ls -lh output/metrics/` |
| Upload simulation | `python upload_to_aws.py --dry-run` |
| Upload tout | `python upload_to_aws.py` |
| Upload date | `python upload_to_aws.py --date 2025-11-04` |
| Upload m√©triques | `python upload_to_aws.py --type metrics` |
| Upload rapports | `python upload_to_aws.py --type reports` |
| Cr√©er tables | `python setup_dynamodb_tables.py` |
| V√©rifier AWS | `aws dynamodb scan --table-name cityflow-metrics --max-items 5` |

---

## üìù Notes

- Les fichiers JSON restent sur EC2 apr√®s upload (backup)
- Les donn√©es ont un TTL de 1 an dans DynamoDB
- Les rapports sont upload√©s dans DynamoDB ET S3
- Le CSV est upload√© uniquement dans S3

---

## üÜò Support

Si vous rencontrez des probl√®mes :

1. V√©rifiez les logs : `cat logs/processing_*.log`
2. Testez la connexion AWS : `aws sts get-caller-identity`
3. V√©rifiez les permissions IAM
4. Utilisez `--dry-run` pour d√©boguer

