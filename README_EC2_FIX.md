# ðŸ”§ Fix EC2 - Mode Fichiers Locaux

## ðŸŽ¯ ProblÃ¨me rÃ©solu

**Avant :** Sur EC2, le traitement Ã©chouait car il essayait de se connecter Ã  DynamoDB qui n'Ã©tait pas configurÃ©.

**Maintenant :** Sur EC2, le systÃ¨me utilise des **fichiers JSON locaux** et vous pouvez uploader manuellement vers AWS quand vous Ãªtes prÃªt.

---

## ðŸ“¦ Fichiers crÃ©Ã©s/modifiÃ©s

### âœ¨ Nouveaux fichiers

1. **`utils/local_file_service.py`** - Service pour gÃ©rer les fichiers JSON locaux
2. **`upload_to_aws.py`** - Script pour uploader vers DynamoDB et S3
3. **`deploy_to_ec2.sh`** - Script pour dÃ©ployer automatiquement sur EC2
4. **`UPLOAD_AWS_GUIDE.md`** - Guide complet d'utilisation
5. **`CHANGEMENTS_EC2.md`** - DÃ©tails techniques des modifications

### ðŸ”„ Fichiers modifiÃ©s

1. **`utils/database_factory.py`** - Utilise LocalFileService sur EC2 au lieu de DynamoDB

---

## ðŸš€ DÃ©ploiement sur EC2

### Option 1 : Script automatique (recommandÃ©)

```bash
# Avec clÃ© SSH
./deploy_to_ec2.sh ec2-user@VOTRE-IP ~/.ssh/votre-cle.pem

# Sans clÃ© SSH (si configurÃ© dans ~/.ssh/config)
./deploy_to_ec2.sh ec2-user@VOTRE-IP
```

Le script :
- âœ… Upload les fichiers automatiquement
- âœ… Teste le systÃ¨me sur EC2
- âœ… Affiche un rÃ©sumÃ© des prochaines Ã©tapes

### Option 2 : Upload manuel via SCP

```bash
# Upload des fichiers
scp -i ~/.ssh/votre-cle.pem utils/local_file_service.py ec2-user@VOTRE-IP:~/cityflow-project/utils/
scp -i ~/.ssh/votre-cle.pem utils/database_factory.py ec2-user@VOTRE-IP:~/cityflow-project/utils/
scp -i ~/.ssh/votre-cle.pem upload_to_aws.py ec2-user@VOTRE-IP:~/cityflow-project/
scp -i ~/.ssh/votre-cle.pem *.md ec2-user@VOTRE-IP:~/cityflow-project/
```

### Option 3 : Via Git (si configurÃ©)

```bash
# En local
git add .
git commit -m "Fix EC2: Utilisation fichiers JSON locaux"
git push

# Sur EC2
ssh ec2-user@VOTRE-IP
cd ~/cityflow-project
git pull
```

---

## ðŸ§ª Test sur EC2

Une fois les fichiers dÃ©ployÃ©s :

```bash
# 1. Se connecter Ã  EC2
ssh -i ~/.ssh/votre-cle.pem ec2-user@VOTRE-IP

# 2. Aller dans le projet
cd ~/cityflow-project

# 3. Tester le nouveau systÃ¨me
python3 << EOF
from utils.database_factory import get_database_service
db = get_database_service()
print("âœ… OK!")
EOF

# 4. Lancer le traitement
./run_processing.sh

# 5. VÃ©rifier les fichiers gÃ©nÃ©rÃ©s
ls -lh output/metrics/
ls -lh output/reports/
```

---

## ðŸ“Š RÃ©sultat attendu

AprÃ¨s le traitement, vous devriez avoir :

```
output/
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ bikes_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ traffic_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ weather_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ comptages_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ chantiers_metrics_2025-11-04.json
â”‚   â””â”€â”€ referentiel_metrics_2025-11-04.json
â””â”€â”€ reports/
    â”œâ”€â”€ daily_report_2025-11-04.json
    â””â”€â”€ daily_report_2025-11-04.csv
```

---

## ðŸ“¤ Upload vers AWS (optionnel)

### PrÃ©requis

1. **Tables DynamoDB crÃ©Ã©es** :
   ```bash
   python setup_dynamodb_tables.py
   ```

2. **Bucket S3 crÃ©Ã©** :
   ```bash
   aws s3 mb s3://cityflow-reports-paris --region eu-west-3
   ```

3. **Role IAM EC2 configurÃ©** avec permissions DynamoDB et S3

### Commandes d'upload

```bash
# Voir ce qui serait uploadÃ© (simulation)
python upload_to_aws.py --dry-run

# Upload tout
python upload_to_aws.py

# Upload seulement une date
python upload_to_aws.py --date 2025-11-04

# Upload seulement les mÃ©triques
python upload_to_aws.py --type metrics

# Upload seulement les rapports
python upload_to_aws.py --type reports
```

---

## âœ… Avantages

| Aspect | BÃ©nÃ©fice |
|--------|----------|
| ðŸš€ **Traitement** | Fonctionne sans DynamoDB |
| ðŸ’° **CoÃ»ts** | Pas d'Ã©critures DynamoDB inutiles |
| ðŸ” **Debugging** | Fichiers JSON lisibles |
| â±ï¸ **FlexibilitÃ©** | Upload quand vous voulez |
| ðŸ“¦ **Backup** | Fichiers locaux + cloud |
| ðŸ§ª **Tests** | Pas besoin d'AWS configurÃ© |

---

## ðŸ“š Documentation complÃ¨te

- **`UPLOAD_AWS_GUIDE.md`** - Guide d'utilisation complet
- **`CHANGEMENTS_EC2.md`** - DÃ©tails techniques

---

## ðŸ” VÃ©rification

### Sur EC2

```bash
# Type de base de donnÃ©es dÃ©tectÃ©
python3 -c "from utils.database_factory import get_database_type; print(get_database_type())"
# Devrait afficher: local_files

# Tester le service
python3 -c "from utils.database_factory import test_database_connection; test_database_connection()"
# Devrait afficher: âœ“ Connexion Ã  la base de donnÃ©es OK
```

### En local (dÃ©veloppement)

```bash
# Type de base de donnÃ©es dÃ©tectÃ©
python3 -c "from utils.database_factory import get_database_type; print(get_database_type())"
# Devrait afficher: mongodb (si bucket-cityflow-paris-s3-raw existe)
```

---

## ðŸ†˜ DÃ©pannage

### Erreur : "No module named 'utils.local_file_service'"

âž¡ï¸ Les fichiers n'ont pas Ã©tÃ© dÃ©ployÃ©s correctement
```bash
./deploy_to_ec2.sh ec2-user@VOTRE-IP ~/.ssh/votre-cle.pem
```

### Erreur : "Permission denied"

âž¡ï¸ Rendre le script exÃ©cutable
```bash
chmod +x deploy_to_ec2.sh
```

### Traitement Ã©choue toujours

âž¡ï¸ VÃ©rifier les logs
```bash
tail -100 logs/processing_*.log
```

---

## ðŸ“ž Support

Si vous rencontrez des problÃ¨mes :

1. âœ… VÃ©rifiez que les fichiers sont bien sur EC2
2. âœ… Testez la dÃ©tection du type de base de donnÃ©es
3. âœ… Lisez les logs de traitement
4. âœ… Consultez `UPLOAD_AWS_GUIDE.md` pour plus de dÃ©tails

---

## ðŸŽ‰ C'est tout !

Le systÃ¨me est maintenant prÃªt Ã  fonctionner sur EC2 sans avoir besoin de DynamoDB pendant le traitement.

**Prochaine Ã©tape :** DÃ©ployer sur EC2 avec `./deploy_to_ec2.sh`

---

**Auteur :** Assistant AI  
**Date :** 2025-11-04  
**Version :** 1.0  
**Statut :** âœ… PrÃªt pour production

