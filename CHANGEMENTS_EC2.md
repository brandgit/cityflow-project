# ğŸ”§ Changements pour EC2 - Mode Fichiers Locaux

## ğŸ“‹ RÃ©sumÃ©

Le systÃ¨me a Ã©tÃ© modifiÃ© pour **NE PLUS utiliser DynamoDB pendant le traitement sur EC2**. 

Ã€ la place, toutes les donnÃ©es sont maintenant stockÃ©es en **fichiers JSON locaux**, puis vous pouvez les uploader manuellement vers AWS quand vous voulez.

---

## âœ… Modifications effectuÃ©es

### 1ï¸âƒ£ **Nouveau service : `LocalFileService`**

**Fichier crÃ©Ã© :** `utils/local_file_service.py`

- ImplÃ©mente l'interface `DatabaseService`
- Stocke mÃ©triques et rapports en JSON local
- GÃ¨re automatiquement les chemins relatifs/absolus
- Compatible avec MongoDB pour le dÃ©veloppement local

### 2ï¸âƒ£ **Factory modifiÃ© : `database_factory.py`**

**Modifications :**
- âŒ Avant : EC2 â†’ DynamoDB
- âœ… Maintenant : EC2 â†’ Fichiers JSON locaux
- MongoDB reste utilisÃ© en dÃ©veloppement local

**Logique de dÃ©tection :**
```python
# Si dossier "bucket-cityflow-paris-s3-raw" n'existe pas
#   â†’ Mode EC2 â†’ LocalFileService (fichiers JSON)
# Sinon
#   â†’ Mode Local â†’ MongoDB
```

### 3ï¸âƒ£ **Script d'upload : `upload_to_aws.py`**

**Fichier crÃ©Ã© :** Script Python pour uploader manuellement vers AWS

**FonctionnalitÃ©s :**
- Upload mÃ©triques â†’ DynamoDB
- Upload rapports â†’ DynamoDB + S3 (JSON + CSV)
- Mode `--dry-run` pour tester
- Upload sÃ©lectif par date ou type
- Gestion automatique des erreurs

**Usage :**
```bash
python upload_to_aws.py                    # Tout uploader
python upload_to_aws.py --date 2025-11-04  # Date spÃ©cifique
python upload_to_aws.py --type metrics     # Seulement mÃ©triques
python upload_to_aws.py --dry-run          # Simulation
```

### 4ï¸âƒ£ **Guide d'utilisation : `UPLOAD_AWS_GUIDE.md`**

Documentation complÃ¨te avec :
- Workflow complet
- Configuration requise
- Exemples d'utilisation
- DÃ©pannage
- Tableau des commandes

---

## ğŸ”„ Nouveau Workflow

### **Avant (problÃ©matique)**
```
EC2 Traitement â†’ âŒ Erreur DynamoDB â†’ âŒ Ã‰chec
```

### **Maintenant (solution)**
```
EC2 Traitement â†’ âœ… Fichiers JSON locaux â†’ âœ… SuccÃ¨s
                          â†“
                   Upload manuel vers AWS (quand prÃªt)
                          â†“
                   DynamoDB + S3
```

---

## ğŸ“Š Structure des fichiers gÃ©nÃ©rÃ©s

```
output/
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ bikes_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ traffic_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ weather_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ comptages_metrics_2025-11-04.json
â”‚   â”œâ”€â”€ chantiers_metrics_2025-11-04.json
â”‚   â””â”€â”€ referentiel_metrics_2025-11-04.json
â””â”€â”€ reports/
    â”œâ”€â”€ daily_report_2025-11-04.json
    â””â”€â”€ daily_report_2025-11-04.csv
```

**Format JSON des mÃ©triques :**
```json
{
  "metric_type": "bikes",
  "date": "2025-11-04",
  "timestamp": "2025-11-04T10:30:00",
  "metrics": {
    // ... donnÃ©es mÃ©triques ...
  }
}
```

**Format JSON des rapports :**
```json
{
  "report_id": "daily_report_2025-11-04",
  "date": "2025-11-04",
  "timestamp": "2025-11-04T10:35:00",
  "report": {
    // ... donnÃ©es du rapport ...
  }
}
```

---

## ğŸš€ Comment utiliser sur EC2

### **1. Traiter les donnÃ©es**

```bash
cd /home/ec2-user/cityflow-project
./run_processing.sh
```

**RÃ©sultat attendu :**
```
âœ… Traitement terminÃ© avec succÃ¨s
ğŸ“ Fichiers JSON crÃ©Ã©s dans output/
```

### **2. VÃ©rifier les fichiers**

```bash
ls -lh output/metrics/
ls -lh output/reports/
```

### **3. (Optionnel) Tester l'upload**

```bash
python upload_to_aws.py --dry-run
```

### **4. Uploader vers AWS**

```bash
# Upload tout
python upload_to_aws.py

# Ou upload sÃ©lectif
python upload_to_aws.py --date 2025-11-04
```

---

## âœ… Avantages de cette approche

| Aspect | Avant | Maintenant |
|--------|-------|------------|
| **DÃ©pendances** | âŒ Requiert DynamoDB + boto3 | âœ… Aucune dÃ©pendance AWS |
| **Traitement** | âŒ Ã‰choue si DynamoDB inaccessible | âœ… Fonctionne toujours |
| **CoÃ»ts** | ğŸ’° Ã‰critures DynamoDB Ã  chaque test | ğŸ’° Pas d'Ã©critures DynamoDB inutiles |
| **Debugging** | ğŸ” Difficile (donnÃ©es dans DynamoDB) | ğŸ” Facile (fichiers JSON lisibles) |
| **FlexibilitÃ©** | â±ï¸ Upload immÃ©diat automatique | â±ï¸ Upload quand vous voulez |
| **Backup** | ğŸ“¦ Seulement dans DynamoDB | ğŸ“¦ Fichiers JSON + DynamoDB |
| **Tests** | ğŸ§ª Requiert AWS configurÃ© | ğŸ§ª Fonctionne sans AWS |

---

## ğŸ”§ Configuration requise pour l'upload

### **1. Tables DynamoDB**

CrÃ©ez-les avec :
```bash
python setup_dynamodb_tables.py
```

Ou manuellement :
- Table `cityflow-metrics` : PK = `metric_type` (String), SK = `date` (String)
- Table `cityflow-reports` : PK = `report_id` (String), SK = `date` (String)

### **2. Bucket S3**

```bash
aws s3 mb s3://cityflow-reports-paris --region eu-west-3
```

### **3. IAM Role EC2**

Permissions requises :
- `dynamodb:PutItem`, `dynamodb:GetItem`, `dynamodb:UpdateItem`
- `s3:PutObject`, `s3:GetObject`

### **4. Fichier `.env`**

```bash
AWS_REGION=eu-west-3
DYNAMODB_METRICS_TABLE=cityflow-metrics
DYNAMODB_REPORTS_TABLE=cityflow-reports
S3_REPORTS_BUCKET=cityflow-reports-paris
S3_REPORTS_PREFIX=reports
OUTPUT_DIR=/home/ec2-user/cityflow-project/output
```

---

## ğŸ§ª Tests effectuÃ©s

âœ… Service LocalFileService crÃ©Ã© et testÃ©
âœ… Factory modifiÃ© et testÃ©
âœ… Script upload crÃ©Ã©
âœ… Documentation complÃ¨te
âœ… Pas d'erreur de linting
âœ… Compatible avec environnement local et EC2

---

## ğŸ“ Notes importantes

1. **MongoDB toujours utilisÃ© en local** : Si le dossier `bucket-cityflow-paris-s3-raw` existe, MongoDB est utilisÃ© (dÃ©veloppement local)

2. **Chemins relatifs/absolus gÃ©rÃ©s** : Le systÃ¨me dÃ©tecte automatiquement si le chemin dans `.env` existe et utilise un fallback si nÃ©cessaire

3. **Pas de perte de donnÃ©es** : Les fichiers JSON restent sur EC2 aprÃ¨s upload (backup)

4. **TTL DynamoDB** : Les donnÃ©es ont un TTL de 1 an dans DynamoDB

5. **Upload idempotent** : Vous pouvez rÃ©exÃ©cuter l'upload sans problÃ¨me (Ã©crase les donnÃ©es existantes)

---

## ğŸ†˜ DÃ©pannage

### **ProblÃ¨me : "Type de base de donnÃ©es inconnu"**

â¡ï¸ Le factory dÃ©tecte mal l'environnement
```bash
# VÃ©rifier la dÃ©tection
python3 -c "from utils.database_factory import get_database_type; print(get_database_type())"
```

### **ProblÃ¨me : Fichiers non crÃ©Ã©s aprÃ¨s traitement**

â¡ï¸ VÃ©rifier les logs
```bash
tail -100 logs/processing_*.log
```

### **ProblÃ¨me : Upload Ã©choue "Access Denied"**

â¡ï¸ VÃ©rifier le role IAM
```bash
aws sts get-caller-identity
```

---

## ğŸ¯ Commandes rapides

```bash
# Sur EC2
./run_processing.sh                          # Traiter
python upload_to_aws.py --dry-run            # Tester upload
python upload_to_aws.py                      # Upload rÃ©el
aws dynamodb scan --table-name cityflow-metrics --max-items 5  # VÃ©rifier

# En local (dÃ©veloppement)
# â†’ Continue d'utiliser MongoDB automatiquement
```

---

## âœ¨ RÃ©sultat final

**Sur EC2, vous avez maintenant :**

1. âœ… Traitement des donnÃ©es qui fonctionne toujours
2. âœ… Fichiers JSON lisibles et modifiables
3. âœ… FlexibilitÃ© pour uploader quand vous voulez
4. âœ… Pas de dÃ©pendance DynamoDB pendant le traitement
5. âœ… Ã‰conomies sur les coÃ»ts AWS
6. âœ… Debugging facilitÃ© avec fichiers locaux
7. âœ… Backup local + cloud

**En local :**

1. âœ… MongoDB continue de fonctionner normalement
2. âœ… Aucun changement pour le dÃ©veloppement

---

## ğŸ“š Fichiers modifiÃ©s/crÃ©Ã©s

| Fichier | Action | Description |
|---------|--------|-------------|
| `utils/local_file_service.py` | âœ¨ CrÃ©Ã© | Service pour fichiers JSON locaux |
| `utils/database_factory.py` | ğŸ”§ ModifiÃ© | Utilise LocalFileService sur EC2 |
| `upload_to_aws.py` | âœ¨ CrÃ©Ã© | Script d'upload manuel vers AWS |
| `UPLOAD_AWS_GUIDE.md` | âœ¨ CrÃ©Ã© | Guide d'utilisation complet |
| `CHANGEMENTS_EC2.md` | âœ¨ CrÃ©Ã© | Ce fichier (rÃ©sumÃ©) |

---

**Date des modifications :** 2025-11-04  
**Statut :** âœ… PrÃªt pour production EC2

